{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:40:53.351605Z","iopub.execute_input":"2025-10-12T09:40:53.351798Z","iopub.status.idle":"2025-10-12T09:40:59.501456Z","shell.execute_reply.started":"2025-10-12T09:40:53.351782Z","shell.execute_reply":"2025-10-12T09:40:59.500505Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (1.0.0rc2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.19.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.3)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (0.28.1)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (0.19.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.10)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface_hub) (8.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"<h1>BERT Sentiment Analysis on IMDb </h1>","metadata":{}},{"cell_type":"markdown","source":"<h3>1. Install Required Libraries </h3>","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate scikit-learn torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:40:59.502917Z","iopub.execute_input":"2025-10-12T09:40:59.503184Z","iopub.status.idle":"2025-10-12T09:42:27.539782Z","shell.execute_reply.started":"2025-10-12T09:40:59.503162Z","shell.execute_reply":"2025-10-12T09:42:27.539065Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"<h3>2. Import Libraries</h3>\n\nimport torch","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom transformers import (\nAutoTokenizer,\nAutoModelForSequenceClassification,\nTrainer,\nTrainingArguments,\nDataCollatorWithPadding\n)\n\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:42:27.540770Z","iopub.execute_input":"2025-10-12T09:42:27.541052Z","iopub.status.idle":"2025-10-12T09:43:07.104600Z","shell.execute_reply.started":"2025-10-12T09:42:27.541024Z","shell.execute_reply":"2025-10-12T09:43:07.103799Z"}},"outputs":[{"name":"stderr","text":"2025-10-12 09:42:47.871368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760262168.252376      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760262168.355090      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"<h3>3. Check GPU</h3>","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device: \", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:07.105415Z","iopub.execute_input":"2025-10-12T09:43:07.105977Z","iopub.status.idle":"2025-10-12T09:43:07.109917Z","shell.execute_reply.started":"2025-10-12T09:43:07.105957Z","shell.execute_reply":"2025-10-12T09:43:07.109135Z"}},"outputs":[{"name":"stdout","text":"Using device:  cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"<h3>4. Load IMDb dataset</h3>","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:07.111668Z","iopub.execute_input":"2025-10-12T09:43:07.111895Z","iopub.status.idle":"2025-10-12T09:43:11.596608Z","shell.execute_reply.started":"2025-10-12T09:43:07.111878Z","shell.execute_reply":"2025-10-12T09:43:11.595989Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291adb55d0f046e686f0f6ab3f3bb82b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51012f5877840eab426a33754ad20bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d1ffcba4324e13864f7e8a488fb80e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba379e644f89446fbce123a8d32170cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd056814c82421b85bbdae042d44d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ae741715764d0fa6850b0f9bfcadee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a350dc85295b4ea8ad4c5dd11de636e6"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(dataset[\"train\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.597326Z","iopub.execute_input":"2025-10-12T09:43:11.598031Z","iopub.status.idle":"2025-10-12T09:43:11.601698Z","shell.execute_reply.started":"2025-10-12T09:43:11.598009Z","shell.execute_reply":"2025-10-12T09:43:11.601023Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 25000\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(dataset[\"train\"][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.602408Z","iopub.execute_input":"2025-10-12T09:43:11.602577Z","iopub.status.idle":"2025-10-12T09:43:11.639943Z","shell.execute_reply.started":"2025-10-12T09:43:11.602563Z","shell.execute_reply":"2025-10-12T09:43:11.639419Z"}},"outputs":[{"name":"stdout","text":"{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.', 'label': 0}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(dataset[\"train\"][1][\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.640668Z","iopub.execute_input":"2025-10-12T09:43:11.640947Z","iopub.status.idle":"2025-10-12T09:43:11.657059Z","shell.execute_reply.started":"2025-10-12T09:43:11.640923Z","shell.execute_reply":"2025-10-12T09:43:11.656372Z"}},"outputs":[{"name":"stdout","text":"\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(dataset[\"train\"][2][\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.657831Z","iopub.execute_input":"2025-10-12T09:43:11.658118Z","iopub.status.idle":"2025-10-12T09:43:11.673989Z","shell.execute_reply.started":"2025-10-12T09:43:11.658101Z","shell.execute_reply":"2025-10-12T09:43:11.673290Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(dataset.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.674691Z","iopub.execute_input":"2025-10-12T09:43:11.674981Z","iopub.status.idle":"2025-10-12T09:43:11.690957Z","shell.execute_reply.started":"2025-10-12T09:43:11.674953Z","shell.execute_reply":"2025-10-12T09:43:11.690368Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['train', 'test', 'unsupervised'])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(dataset[\"train\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.691782Z","iopub.execute_input":"2025-10-12T09:43:11.691997Z","iopub.status.idle":"2025-10-12T09:43:11.707288Z","shell.execute_reply.started":"2025-10-12T09:43:11.691982Z","shell.execute_reply":"2025-10-12T09:43:11.706698Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 25000\n})\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(type(dataset[\"train\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.707947Z","iopub.execute_input":"2025-10-12T09:43:11.708255Z","iopub.status.idle":"2025-10-12T09:43:11.725875Z","shell.execute_reply.started":"2025-10-12T09:43:11.708238Z","shell.execute_reply":"2025-10-12T09:43:11.725236Z"}},"outputs":[{"name":"stdout","text":"<class 'datasets.arrow_dataset.Dataset'>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(dataset[\"train\"][2].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.726528Z","iopub.execute_input":"2025-10-12T09:43:11.726769Z","iopub.status.idle":"2025-10-12T09:43:11.743847Z","shell.execute_reply.started":"2025-10-12T09:43:11.726753Z","shell.execute_reply":"2025-10-12T09:43:11.743343Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['text', 'label'])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(dataset[\"train\"][2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.746247Z","iopub.execute_input":"2025-10-12T09:43:11.746479Z","iopub.status.idle":"2025-10-12T09:43:11.761002Z","shell.execute_reply.started":"2025-10-12T09:43:11.746465Z","shell.execute_reply":"2025-10-12T09:43:11.760477Z"}},"outputs":[{"name":"stdout","text":"{'text': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\", 'label': 0}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"<h3>5. Load Tokenizer</h3>","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:11.761722Z","iopub.execute_input":"2025-10-12T09:43:11.761944Z","iopub.status.idle":"2025-10-12T09:43:12.741685Z","shell.execute_reply.started":"2025-10-12T09:43:11.761921Z","shell.execute_reply":"2025-10-12T09:43:12.740996Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3784dcee1140a6ad5f9b2cea14fe7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c4ef2cff2046f49bc9fbc4d96e7909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de18b38ffdc84deda1a9dc513b168a52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15c7b527162407c80691a40e77fe51c"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"<h3>Create Tokenize Text Function</h3>","metadata":{}},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(\n        example[\"text\"],\n        truncation=True,\n        padding=False,\n        max_length=256\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:12.742511Z","iopub.execute_input":"2025-10-12T09:43:12.742711Z","iopub.status.idle":"2025-10-12T09:43:12.746736Z","shell.execute_reply.started":"2025-10-12T09:43:12.742695Z","shell.execute_reply":"2025-10-12T09:43:12.746023Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"<h3>Apply Tokenization</h3>","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:12.747587Z","iopub.execute_input":"2025-10-12T09:43:12.748028Z","iopub.status.idle":"2025-10-12T09:44:04.455961Z","shell.execute_reply.started":"2025-10-12T09:43:12.748010Z","shell.execute_reply":"2025-10-12T09:44:04.454993Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6930d5a43f7b4af9953efdf519ea13a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dff92e4ef6fa4af2ab12826eb47ce971"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4c8655480e44fe873b11463a49d350"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"<h3>Prepare Data for PyTorch</h3>","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:44:04.456991Z","iopub.execute_input":"2025-10-12T09:44:04.457461Z","iopub.status.idle":"2025-10-12T09:44:04.461582Z","shell.execute_reply.started":"2025-10-12T09:44:04.457430Z","shell.execute_reply":"2025-10-12T09:44:04.460651Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"<h3>Prepare Data for PyTorch</h3>","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:44:04.462378Z","iopub.execute_input":"2025-10-12T09:44:04.463201Z","iopub.status.idle":"2025-10-12T09:44:04.912270Z","shell.execute_reply.started":"2025-10-12T09:44:04.463177Z","shell.execute_reply":"2025-10-12T09:44:04.911455Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data_collator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:44:04.912965Z","iopub.execute_input":"2025-10-12T09:44:04.913207Z","iopub.status.idle":"2025-10-12T09:44:04.930525Z","shell.execute_reply.started":"2025-10-12T09:44:04.913190Z","shell.execute_reply":"2025-10-12T09:44:04.929784Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"<h3>Rename \"label\" to \"labels\" (Trainer expects that)</h3>","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\ntokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\ntrain_dataset = tokenized_dataset[\"train\"]\ntest_dataset = tokenized_dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:44:04.931198Z","iopub.execute_input":"2025-10-12T09:44:04.931405Z","iopub.status.idle":"2025-10-12T09:44:04.953876Z","shell.execute_reply.started":"2025-10-12T09:44:04.931390Z","shell.execute_reply":"2025-10-12T09:44:04.953205Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_dataset = tokenized_dataset[\"train\"]\ntest_dataset = tokenized_dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:44:04.954687Z","iopub.execute_input":"2025-10-12T09:44:04.955033Z","iopub.status.idle":"2025-10-12T09:44:04.966557Z","shell.execute_reply.started":"2025-10-12T09:44:04.955006Z","shell.execute_reply":"2025-10-12T09:44:04.965923Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"<h3>Load Pretrained Model</h3>","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels = 2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:55:59.202621Z","iopub.execute_input":"2025-10-12T09:55:59.203402Z","iopub.status.idle":"2025-10-12T09:55:59.336652Z","shell.execute_reply.started":"2025-10-12T09:55:59.203373Z","shell.execute_reply":"2025-10-12T09:55:59.335923Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"<h3>Define Evaluation Metrics</h3>","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n    acc = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:56:00.666888Z","iopub.execute_input":"2025-10-12T09:56:00.667172Z","iopub.status.idle":"2025-10-12T09:56:00.671279Z","shell.execute_reply.started":"2025-10-12T09:56:00.667153Z","shell.execute_reply":"2025-10-12T09:56:00.670581Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"<h3>Training Arguments<h3>","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",           # Where to save checkpoints\n    eval_strategy=\"epoch\",            # Evaluate at the end of each epoch\n    save_strategy=\"epoch\",            # Save model at the end of each epoch\n    learning_rate=2e-5,               # Typical for BERT fine-tuning\n    per_device_train_batch_size=16,   # Batch size per GPU\n    per_device_eval_batch_size=16,    # Eval batch size per GPU\n    num_train_epochs=2,               # Number of epochs\n    weight_decay=0.01,                # L2 regularization\n    load_best_model_at_end=True,      # Automatically load best model\n    logging_dir=\"./logs\",             # TensorBoard / logging dir\n    logging_steps=50,                 # Print logs every 50 steps\n    report_to=\"none\",                 # Disable wandb to avoid warnings\n    fp16=True,                         # Enable mixed precision for faster GPU training\n    dataloader_pin_memory=True         # Speed up data transfer to GPU\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:56:03.830579Z","iopub.execute_input":"2025-10-12T09:56:03.831187Z","iopub.status.idle":"2025-10-12T09:56:03.863930Z","shell.execute_reply.started":"2025-10-12T09:56:03.831162Z","shell.execute_reply":"2025-10-12T09:56:03.863204Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"<h3>Trainer Setup</h3>","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:56:07.420643Z","iopub.execute_input":"2025-10-12T09:56:07.421157Z","iopub.status.idle":"2025-10-12T09:56:07.623584Z","shell.execute_reply.started":"2025-10-12T09:56:07.421132Z","shell.execute_reply":"2025-10-12T09:56:07.622900Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/3156397598.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"<h3>Fine Tune Model</h3>","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:56:23.781720Z","iopub.execute_input":"2025-10-12T09:56:23.782262Z","iopub.status.idle":"2025-10-12T10:25:19.662234Z","shell.execute_reply.started":"2025-10-12T09:56:23.782236Z","shell.execute_reply":"2025-10-12T10:25:19.661594Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1564/1564 28:52, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.228300</td>\n      <td>0.200876</td>\n      <td>0.920520</td>\n      <td>0.919856</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.142000</td>\n      <td>0.220739</td>\n      <td>0.922840</td>\n      <td>0.923528</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1564, training_loss=0.2086804359770187, metrics={'train_runtime': 1735.3528, 'train_samples_per_second': 28.813, 'train_steps_per_second': 0.901, 'total_flos': 6577776384000000.0, 'train_loss': 0.2086804359770187, 'epoch': 2.0})"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"metrics = trainer.evaluate()\nprint(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T10:33:22.726743Z","iopub.execute_input":"2025-10-12T10:33:22.727428Z","iopub.status.idle":"2025-10-12T10:36:55.611516Z","shell.execute_reply.started":"2025-10-12T10:33:22.727406Z","shell.execute_reply":"2025-10-12T10:36:55.610812Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [782/782 03:32]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.2008763998746872, 'eval_accuracy': 0.92052, 'eval_f1': 0.9198564110837737, 'eval_runtime': 212.8758, 'eval_samples_per_second': 117.439, 'eval_steps_per_second': 3.674, 'epoch': 2.0}\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_bert_imdb\")\ntokenizer.save_pretrained(\"./fine_tuned_bert_imdb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T10:37:19.780598Z","iopub.execute_input":"2025-10-12T10:37:19.781173Z","iopub.status.idle":"2025-10-12T10:37:20.474703Z","shell.execute_reply.started":"2025-10-12T10:37:19.781150Z","shell.execute_reply":"2025-10-12T10:37:20.473989Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_bert_imdb/tokenizer_config.json',\n './fine_tuned_bert_imdb/special_tokens_map.json',\n './fine_tuned_bert_imdb/vocab.txt',\n './fine_tuned_bert_imdb/added_tokens.json',\n './fine_tuned_bert_imdb/tokenizer.json')"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"sample_text = \"shit\"\ninputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\noutputs = model(**inputs)\npred = torch.argmax(outputs.logits, dim=1).item()\nlabel = \"Positive\" if pred == 1 else \"Negative\"\nprint(f\"Review: {sample_text}\\nPrediction: {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T10:52:07.932205Z","iopub.execute_input":"2025-10-12T10:52:07.932482Z","iopub.status.idle":"2025-10-12T10:52:07.950002Z","shell.execute_reply.started":"2025-10-12T10:52:07.932461Z","shell.execute_reply":"2025-10-12T10:52:07.949260Z"}},"outputs":[{"name":"stdout","text":"Review: shit\nPrediction: Negative\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}